Environment:
	Python: 3.10.12
	PyTorch: 1.12.1
	Torchvision: 0.13.1
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.26.0
	PIL: 10.0.1
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 16, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 16
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
Environment:
	Python: 3.10.12
	PyTorch: 1.12.1
	Torchvision: 0.13.1
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.26.0
	PIL: 10.0.1
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 8, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 8
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
D:\Users\wuyux\anaconda3\envs\domainbed\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
D:\Users\wuyux\anaconda3\envs\domainbed\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.1958511287  0.1955990220  0.1812366738  0.1816239316  0.2193113772  0.2005988024  0.0512086514  0.0496815287  0.0000000000  2.2696068287  0.6019635201  0             67.999235868 
0.9420378279  0.8655256724  0.9552238806  0.9123931624  0.9872754491  0.9401197605  0.5238549618  0.5414012739  1.7964071856  0.3340990233  0.7000021935  300           0.1638520122 
0.8529591214  0.7872860636  0.9253731343  0.8760683761  0.9648203593  0.8952095808  0.6599872774  0.6420382166  3.5928143713  0.0919913825  0.7000021935  600           0.1718888871 
0.9926784625  0.9193154034  0.9866737740  0.9273504274  0.9977544910  0.9580838323  0.6020992366  0.6000000000  5.3892215569  0.0472272644  0.7000021935  900           0.1695434634 
0.9969493594  0.9144254279  0.9941364606  0.9294871795  0.9985029940  0.9520958084  0.6001908397  0.5808917197  7.1856287425  0.0390688198  0.7000021935  1200          0.1705973148 
1.0000000000  0.9339853301  0.9989339019  0.9465811966  0.9992514970  0.9550898204  0.7076972010  0.7121019108  8.9820359281  0.0112727781  0.7000021935  1500          0.1711558199 
0.9963392312  0.9315403423  0.9973347548  0.9465811966  0.9940119760  0.9401197605  0.6943384224  0.6840764331  10.778443113  0.0264132636  0.7000021935  1800          0.1724889247 
1.0000000000  0.9290953545  1.0000000000  0.9487179487  1.0000000000  0.9640718563  0.6466284987  0.6484076433  12.574850299  0.0099450280  0.7000021935  2100          0.1715048893 
1.0000000000  0.9217603912  1.0000000000  0.9529914530  1.0000000000  0.9730538922  0.6504452926  0.6292993631  14.371257485  0.0005295032  0.7000021935  2400          0.1739948972 
1.0000000000  0.9266503667  1.0000000000  0.9529914530  1.0000000000  0.9730538922  0.6609414758  0.6471337580  16.167664670  0.0000556398  0.7000021935  2700          0.1818673595 
1.0000000000  0.9242053790  1.0000000000  0.9508547009  1.0000000000  0.9730538922  0.6666666667  0.6547770701  17.964071856  0.0000389793  0.7000021935  3000          0.1891542411 
1.0000000000  0.9266503667  1.0000000000  0.9508547009  1.0000000000  0.9730538922  0.6676208651  0.6560509554  19.760479041  0.0000213937  0.7000021935  3300          0.1866005357 
1.0000000000  0.9266503667  1.0000000000  0.9508547009  1.0000000000  0.9730538922  0.6695292621  0.6560509554  21.556886227  0.0000174875  0.7000021935  3600          0.1935759179 
1.0000000000  0.9266503667  1.0000000000  0.9508547009  1.0000000000  0.9730538922  0.6698473282  0.6560509554  23.353293413  0.0000131708  0.7000021935  3900          0.1786705589 
1.0000000000  0.9266503667  1.0000000000  0.9529914530  1.0000000000  0.9730538922  0.6736641221  0.6573248408  25.149700598  0.0000104120  0.7000021935  4200          0.1800832272 
1.0000000000  0.9266503667  1.0000000000  0.9508547009  1.0000000000  0.9700598802  0.6708015267  0.6598726115  26.946107784  0.0000081443  0.7000021935  4500          0.1896550449 
1.0000000000  0.9266503667  1.0000000000  0.9529914530  1.0000000000  0.9730538922  0.6746183206  0.6636942675  28.742514970  0.0000060487  0.7000021935  4800          0.1785616223 
1.0000000000  0.9266503667  1.0000000000  0.9529914530  1.0000000000  0.9730538922  0.6743002545  0.6636942675  29.940119760  0.0000055475  0.7000021935  5000          0.1870605004
Environment:
	Python: 3.10.12
	PyTorch: 1.12.1
	Torchvision: 0.13.1
	CUDA: 11.3
	CUDNN: 8302
	NumPy: 1.26.0
	PIL: 10.0.1
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/PACS_edge/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 8, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 8
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
D:\Users\wuyux\anaconda3\envs\domainbed\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
D:\Users\wuyux\anaconda3\envs\domainbed\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.1561928005  0.1149144254  0.1823027719  0.1495726496  0.1339820359  0.1437125749  0.1253180662  0.1095541401  0.0000000000  2.0800325871  0.6019635201  0             37.917980909 
0.7291031117  0.6283618582  0.8001066098  0.7264957265  0.8300898204  0.7185628743  0.5677480916  0.6025477707  1.7964071856  0.8065385808  0.7000021935  300           0.1571933174 
0.8852959121  0.7114914425  0.9035181237  0.8205128205  0.9491017964  0.7964071856  0.7331424936  0.7528662420  3.5928143713  0.3192377030  0.7000021935  600           0.1658597747 
0.9725442343  0.7677261614  0.9813432836  0.8547008547  0.9895209581  0.8113772455  0.7194656489  0.7477707006  5.3892215569  0.1366438002  0.7000021935  900           0.1657733377 
0.9865771812  0.7530562347  0.9893390192  0.8632478632  0.9947604790  0.8323353293  0.7725826972  0.7872611465  7.1856287425  0.0813669820  0.7000021935  1200          0.1668254526 
0.9847467968  0.7457212714  0.9861407249  0.8632478632  0.9917664671  0.8383233533  0.7363231552  0.7452229299  8.9820359281  0.0447957555  0.7000021935  1500          0.1673945864 
0.9902379500  0.7555012225  0.9888059701  0.8632478632  0.9932634731  0.8053892216  0.7048346056  0.7337579618  10.778443113  0.0296375043  0.7000021935  1800          0.1663131873 
0.9713239780  0.7432762836  0.9818763326  0.8226495726  0.9872754491  0.8023952096  0.7070610687  0.7388535032  12.574850299  0.0306497706  0.7000021935  2100          0.1660725387 
0.9969493594  0.7555012225  0.9989339019  0.8952991453  0.9985029940  0.7994011976  0.6701653944  0.7082802548  14.371257485  0.0151573246  0.7000021935  2400          0.1663182886 
0.9969493594  0.7677261614  0.9973347548  0.8696581197  0.9985029940  0.8053892216  0.7236005089  0.7350318471  16.167664670  0.0133473229  0.7000021935  2700          0.1662508051 
0.9530201342  0.7310513447  0.9760127932  0.8440170940  0.9648203593  0.7694610778  0.6765267176  0.6929936306  17.964071856  0.0256389209  0.7000021935  3000          0.1664226055 
0.9871873093  0.7383863081  0.9978678038  0.8760683761  0.9985029940  0.8413173653  0.7767175573  0.7745222930  19.760479041  0.0216464534  0.7000021935  3300          0.1672974340 
0.9969493594  0.7823960880  0.9936034115  0.8632478632  0.9992514970  0.8263473054  0.7439567430  0.7783439490  21.556886227  0.0502244984  0.7000021935  3600          0.1666798536 
0.9993898719  0.7897310513  0.9989339019  0.8803418803  1.0000000000  0.8443113772  0.7045165394  0.7146496815  23.353293413  0.0152758006  0.7000021935  3900          0.1667281397 
1.0000000000  0.7897310513  0.9989339019  0.8846153846  1.0000000000  0.8473053892  0.7538167939  0.7732484076  25.149700598  0.0111851983  0.7000021935  4200          0.1663402303 
0.9987797437  0.7775061125  1.0000000000  0.8995726496  1.0000000000  0.8622754491  0.7344147583  0.7515923567  26.946107784  0.0030829371  0.7000021935  4500          0.1669395852 
0.9993898719  0.7726161369  0.9984008529  0.8717948718  0.9977544910  0.8383233533  0.7175572519  0.7439490446  28.742514970  0.0349552446  0.7000021935  4800          0.1670193585 
0.9987797437  0.7603911980  0.9989339019  0.8589743590  0.9992514970  0.8712574850  0.7105597964  0.7414012739  29.940119760  0.0115524197  0.7000021935  5000          0.1653976774 
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Gaussian\train.py", line 99, in <module>
    dataset = vars(datasets)[args.dataset](args.data_dir,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Gaussian\domainbed\datasets.py", line 257, in __init__
    super().__init__(self.dir, test_envs, hparams['data_augmentation'], hparams)
  File "C:\gitcode\DomainGeneralizeEx_Gaussian\domainbed\datasets.py", line 197, in __init__
    environments = [f.name for f in os.scandir(root) if f.is_dir()]
                                    ^^^^^^^^^^^^^^^^
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: './domainbed/data/PACS/'
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.2367297132  0.2249388753  0.2425373134  0.2414529915  0.2260479042  0.1886227545  0.1342239186  0.1171974522  0.0000000000  2.1496033669  0.0000000000  0             3.4911718369 
0.9975594875  0.8997555012  0.9930703625  0.9337606838  0.9985029940  0.9341317365  0.6262722646  0.6140127389  7.1856287425  0.1804423405  0.0000000000  300           4.1925600410 
1.0000000000  0.9070904645  1.0000000000  0.9423076923  1.0000000000  0.9550898204  0.6377226463  0.6229299363  14.371257485  0.0078771276  0.0000000000  600           4.0418166542 
1.0000000000  0.9144254279  1.0000000000  0.9444444444  1.0000000000  0.9580838323  0.6459923664  0.6445859873  21.556886227  0.0001416284  0.0000000000  900           4.0366875513 
1.0000000000  0.9119804401  1.0000000000  0.9423076923  1.0000000000  0.9550898204  0.6437659033  0.6369426752  28.742514970  0.0000437539  0.0000000000  1200          4.6022403320 
1.0000000000  0.9193154034  1.0000000000  0.9423076923  1.0000000000  0.9550898204  0.6440839695  0.6318471338  35.928143712  0.0000253550  0.0000000000  1500          4.0211479362 
1.0000000000  0.9144254279  1.0000000000  0.9444444444  1.0000000000  0.9520958084  0.6412213740  0.6254777070  43.113772455  0.0000162724  0.0000000000  1800          4.1113484542 
1.0000000000  0.9168704156  1.0000000000  0.9444444444  1.0000000000  0.9550898204  0.6370865140  0.6267515924  50.299401197  0.0000110838  0.0000000000  2100          4.1145304529 
1.0000000000  0.9168704156  1.0000000000  0.9444444444  1.0000000000  0.9550898204  0.6354961832  0.6254777070  57.485029940  0.0000084871  0.0000000000  2400          4.0369875169 
1.0000000000  0.9144254279  1.0000000000  0.9444444444  1.0000000000  0.9550898204  0.6323155216  0.6292993631  64.670658682  0.0000065440  0.0000000000  2700          4.1931121778 
1.0000000000  0.9168704156  1.0000000000  0.9444444444  1.0000000000  0.9550898204  0.6304071247  0.6292993631  71.856287425  0.0000050673  0.0000000000  3000          4.0095602584 
1.0000000000  0.9144254279  1.0000000000  0.9487179487  1.0000000000  0.9550898204  0.6304071247  0.6305732484  79.041916167  0.0000042107  0.0000000000  3300          4.1563365412 
1.0000000000  0.9144254279  1.0000000000  0.9465811966  1.0000000000  0.9550898204  0.6275445293  0.6267515924  86.227544910  0.0000032970  0.0000000000  3600          4.0107326380 
1.0000000000  0.9119804401  1.0000000000  0.9487179487  1.0000000000  0.9550898204  0.6272264631  0.6267515924  93.413173652  0.0000026705  0.0000000000  3900          4.0736580118 
1.0000000000  0.9144254279  1.0000000000  0.9487179487  1.0000000000  0.9550898204  0.6265903308  0.6229299363  100.59880239  0.0000021324  0.0000000000  4200          4.0582299733 
1.0000000000  0.9119804401  1.0000000000  0.9487179487  1.0000000000  0.9550898204  0.6253180662  0.6191082803  107.78443113  0.0000017207  0.0000000000  4500          3.9851214226 
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 1345, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 1371, in _process_data
    data.reraise()
  File "C:\anaconda1\Lib\site-packages\torch\_utils.py", line 644, in reraise
    raise exception
cv2.error: Caught error in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\datasets.py", line 196, in __call__
    equalized=cv2.equalizeHist(img)
              ^^^^^^^^^^^^^^^^^^^^^
cv2.error: OpenCV(4.6.0) C:\b\abs_f8n1j3l9l0\croot\opencv-suite_1691622637237\work\modules\imgproc\src\histogram.cpp:3440: error: (-215:Assertion failed) _src.type() == CV_8UC1 in function 'cv::equalizeHist'


Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\datasets.py", line 195, in __call__
    equalized=cv2.equalizeHist(img)
              ^^^^^^^^^^^^^^^^^^^^^
cv2.error: OpenCV(4.6.0) C:\b\abs_f8n1j3l9l0\croot\opencv-suite_1691622637237\work\modules\imgproc\src\histogram.cpp:3440: error: (-215:Assertion failed) _src.type() == CV_8UC1 in function 'cv::equalizeHist'

Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\datasets.py", line 193, in __call__
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
cv2.error: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'cvtColor'
> Overload resolution failed:
>  - src is not a numpy array, neither a scalar
>  - Expected Ptr<cv::UMat> for argument 'src'

Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 277, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\functional.py", line 363, in normalize
    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\_functional_tensor.py", line 928, in normalize
    return tensor.sub_(mean).div_(std)
           ^^^^^^^^^^^^^^^^^
RuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 277, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\functional.py", line 363, in normalize
    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\_functional_tensor.py", line 928, in normalize
    return tensor.sub_(mean).div_(std)
           ^^^^^^^^^^^^^^^^^
RuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\datasets.py", line 193, in __call__
    (b, g, r) = cv2.split(img)
                ^^^^^^^^^^^^^^
cv2.error: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'split'
> Overload resolution failed:
>  - m is not a numpy array, neither a scalar
>  - Expected Ptr<cv::UMat> for argument 'm'

Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\datasets.py", line 195, in __call__
    (b, g, r) = cv2.split(img)
                ^^^^^^^^^^^^^^
cv2.error: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'split'
> Overload resolution failed:
>  - m is not a numpy array, neither a scalar
>  - Expected Ptr<cv::UMat> for argument 'm'

Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\datasets.py", line 195, in __call__
    (b, g, r) = cv2.split(img)
                ^^^^^^^^^^^^^^
cv2.error: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'split'
> Overload resolution failed:
>  - m is not a numpy array, neither a scalar
>  - Expected Ptr<cv::UMat> for argument 'm'

Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "C:\gitcode\DomainGeneralizeEx_Equalized\train.py", line 210, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\lib\misc.py", line 138, in __getitem__
    return self.underlying_dataset[self.keys[key]]
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda1\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\gitcode\DomainGeneralizeEx_Equalized\domainbed\datasets.py", line 200, in __call__
    result = cv2.merge(bH, gH, rH)
             ^^^^^^^^^^^^^^^^^^^^^
cv2.error: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'merge'
> Overload resolution failed:
>  - merge() takes at most 2 arguments (3 given)
>  - merge() takes at most 2 arguments (3 given)

Environment:
	Python: 3.11.5
	PyTorch: 2.0.1
	Torchvision: 0.15.2a0
	CUDA: None
	CUDNN: None
	NumPy: 1.24.3
	PIL: 9.4.0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"resnet18": true, "batch_size": 32, "data_augmentation": false}
	hparams_seed: 0
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: False
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: True
	resnet_dropout: 0.0
	weight_decay: 0.0
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\anaconda1\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.2202562538  0.2127139364  0.2030916844  0.2051282051  0.1923652695  0.1556886228  0.1230916031  0.1248407643  0.0000000000  2.1937909126  0.0000000000  0             4.3089070320 
0.9963392312  0.9168704156  0.9936034115  0.8824786325  1.0000000000  0.9461077844  0.6173664122  0.6152866242  7.1856287425  0.2101353472  0.0000000000  300           5.0806772391 
1.0000000000  0.9095354523  1.0000000000  0.9145299145  1.0000000000  0.9491017964  0.6513994911  0.6369426752  14.371257485  0.0144804855  0.0000000000  600           5.1373388608 
1.0000000000  0.9193154034  1.0000000000  0.9102564103  1.0000000000  0.9491017964  0.6533078880  0.6484076433  21.556886227  0.0002654327  0.0000000000  900           5.0707574312 
1.0000000000  0.9217603912  1.0000000000  0.9081196581  1.0000000000  0.9491017964  0.6517175573  0.6458598726  28.742514970  0.0000593740  0.0000000000  1200          5.1226644492 
1.0000000000  0.9168704156  1.0000000000  0.9059829060  1.0000000000  0.9520958084  0.6513994911  0.6458598726  35.928143712  0.0000316108  0.0000000000  1500          5.1497111718 
1.0000000000  0.9193154034  1.0000000000  0.9059829060  1.0000000000  0.9520958084  0.6479007634  0.6433121019  43.113772455  0.0000206597  0.0000000000  1800          5.0919547399 
1.0000000000  0.9217603912  1.0000000000  0.9059829060  1.0000000000  0.9520958084  0.6453562341  0.6420382166  50.299401197  0.0000141630  0.0000000000  2100          4.3231157660 
1.0000000000  0.9168704156  1.0000000000  0.9081196581  1.0000000000  0.9520958084  0.6456743003  0.6433121019  57.485029940  0.0000102900  0.0000000000  2400          4.0759421674 
1.0000000000  0.9168704156  1.0000000000  0.9059829060  1.0000000000  0.9520958084  0.6459923664  0.6343949045  64.670658682  0.0000082240  0.0000000000  2700          5.1578481158 
1.0000000000  0.9193154034  1.0000000000  0.9059829060  1.0000000000  0.9520958084  0.6421755725  0.6331210191  71.856287425  0.0000062806  0.0000000000  3000          4.8281363948 
1.0000000000  0.9193154034  1.0000000000  0.9059829060  1.0000000000  0.9520958084  0.6421755725  0.6305732484  79.041916167  0.0000050211  0.0000000000  3300          4.0814951928 
1.0000000000  0.9193154034  1.0000000000  0.9081196581  1.0000000000  0.9520958084  0.6409033079  0.6331210191  86.227544910  0.0000039392  0.0000000000  3600          5.0439421320 
1.0000000000  0.9168704156  1.0000000000  0.9081196581  1.0000000000  0.9520958084  0.6412213740  0.6292993631  93.413173652  0.0000032206  0.0000000000  3900          5.0286885039 
1.0000000000  0.9193154034  1.0000000000  0.9081196581  1.0000000000  0.9520958084  0.6399491094  0.6280254777  100.59880239  0.0000026066  0.0000000000  4200          4.3437790298 
1.0000000000  0.9193154034  1.0000000000  0.9081196581  1.0000000000  0.9520958084  0.6370865140  0.6267515924  107.78443113  0.0000021206  0.0000000000  4500          4.2733048161 
1.0000000000  0.9168704156  1.0000000000  0.9102564103  1.0000000000  0.9520958084  0.6389949109  0.6292993631  114.97005988  0.0000017611  0.0000000000  4800          4.0620675691 
1.0000000000  0.9193154034  1.0000000000  0.9102564103  1.0000000000  0.9520958084  0.6380407125  0.6267515924  119.76047904  0.0000013981  0.0000000000  5000          4.0709983563 
